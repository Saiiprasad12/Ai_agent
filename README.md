ğŸ‚¡ ğŸ‚± ğŸ‚½ Local Ai Agent ğŸƒ ğŸƒ” ğŸ‚®
Uno rules, manuals, PDFs... the AI always plays the right card.

# Local PDF RAG Agent Using Ollama + LangChain

Ask questions to any PDF using fully local AI models. This project uses Retrieval-Augmented Generation (RAG) to extract meaningful context from documents and generate accurate answers, all while keeping data private on your machine.

Perfect for rulebooks, manuals, reportsâ€¦ and in this case: Uno game rules!

âœ… Features

â€¢ Local inference through Ollama
â€¢ Uses embeddings to retrieve the most relevant PDF chunks
â€¢ Interactive chat interface in the terminal
â€¢ Prevents hallucination with context-aware prompting
â€¢ Swap AI models easily (Mistral, Llama, etc.)
â€¢ Lightweight in-memory vector store

ğŸ”§ Tech Stack
Component	Tool
LLM	Mistral via Ollama
Embeddings	nomic-embed-text
Framework	LangChain
Vector Store	DocArray In-Memory Search
Document Loader	PyPDFLoader
Language	Python 3.10+
ğŸ“¦ Prerequisites

Install Python and Ollama:

â€¢ Download Ollama: https://ollama.ai/download

â€¢ Pull required models:

ollama pull mistral
ollama pull nomic-embed-text

ğŸš€ Installation
git clone https://github.com/<your-username>/<your-repo-name>.git
cd <your-repo-name>

python -m venv venv
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

pip install -r requirements.txt

â–¶ï¸ How to Run

Start Ollama:

ollama serve


Run the agent:

python main.py sample_docs/uno_rules.pdf


Ask your questions!

Your Question: What is a Wild Draw 4 card?


Exit anytime using:

exit


or

quit

ğŸ“ Project Structure
.
â”œâ”€â”€ main.py
â”œâ”€â”€ sample_docs/
â”‚   â””â”€â”€ uno_rules.pdf  (optional example)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

ğŸ’¡ Example Questions

â€¢ What is the main objective of Uno?
â€¢ When can a Draw 2 card be played?
â€¢ What does a Reverse card do?

ğŸ›  Troubleshooting
Issue	Possible Fix
Model fails to load	Check if Ollama is running: ollama serve
PDF not found	Confirm correct file path
Slow first-time response	Model is loading for the first run
ğŸ—º Roadmap

â€¢ Support multiple PDFs
â€¢ RAG UI using Streamlit
â€¢ Chat history memory
â€¢ GPU performance optimizations
â€¢ Docker support for easy deployment

ğŸ¤ Contributions

Open to improvements. PRs welcome!

ğŸ“œ License

MIT License. Use and modify freely.

ğŸ™Œ Credits

â€¢ LangChain community
â€¢ Ollama team
â€¢ Uno card game creators (fun guaranteed)
